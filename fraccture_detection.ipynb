{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1i8j-F0Lm33G9v3uBvHbUxSUU1AwNSRay",
      "authorship_tag": "ABX9TyP17/QawX3CqR6CgktKpoF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/am-SaadSiddiqui/rad.ai/blob/main/fraccture_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipFPl-5K5jTT"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "metadata": {
        "id": "U82jQg9U6K1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WhZMO71I0Tn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_generator = generator.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Dataset_NexusHackathon\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "Validation_generator = generator.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Dataset_NexusHackathon\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qgxz0j76UaP",
        "outputId": "81cd2d9e-dcac-4d62-c759-9fce21c99312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 874 images belonging to 2 classes.\n",
            "Found 218 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-41r9Of3tXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_generator.next()[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6aGupkr62L-",
        "outputId": "748fadc0-ef32-4dff-f665-93c984934a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Validation_generator.next()[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9Pg83Ht7DnN",
        "outputId": "a6e25baf-abf3-4515-f6ba-28e51670e9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "r-q6WNvI7Jzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.Xception(\n",
        "    weights=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "metadata": {
        "id": "RntnjvO87PMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "xS_csbog7Vh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=True)\n",
        "x = keras.layers.GaussianNoise(0.25)(x)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dense(512,activation='relu')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.GaussianNoise(0.25)(x)\n",
        "x = keras.layers.Dropout(0.25)(x)\n",
        "outputs = keras.layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "0Cauupv37Zfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks"
      ],
      "metadata": {
        "id": "D6P9vRVC7deA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = keras.callbacks.EarlyStopping(\n",
        "    patience=7,\n",
        ")\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "_pS1s25b7ho6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "42JOXcm97ojw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Train_generator, epochs=20,\n",
        "          callbacks=[earlyStopping,model_checkpoint_callback ],\n",
        "          validation_data=Validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re-melXm7ssS",
        "outputId": "1c632ea8-22a4-4946-ba66-49c566a3df32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "55/55 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.8169"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/55 [==============================] - 90s 818ms/step - loss: 0.5201 - accuracy: 0.8169 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "55/55 [==============================] - 14s 261ms/step - loss: 0.1490 - accuracy: 0.9908 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "55/55 [==============================] - 15s 269ms/step - loss: 0.0612 - accuracy: 0.9977 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "55/55 [==============================] - 15s 270ms/step - loss: 0.0352 - accuracy: 0.9989 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "55/55 [==============================] - 15s 269ms/step - loss: 0.0200 - accuracy: 0.9989 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0152 - accuracy: 0.9989 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "55/55 [==============================] - 15s 265ms/step - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "55/55 [==============================] - 15s 267ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "55/55 [==============================] - 15s 267ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "55/55 [==============================] - 15s 276ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "55/55 [==============================] - 15s 267ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "55/55 [==============================] - 15s 270ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "55/55 [==============================] - 15s 271ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 5.5442e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 4.2718e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "55/55 [==============================] - 15s 266ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 7.4273e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "55/55 [==============================] - 15s 268ms/step - loss: 0.0090 - accuracy: 0.9989 - val_loss: 7.1742e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f684c3c2aa0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpcD_MvQJY0D",
        "outputId": "7a77be27-3ab4-49c9-de58-31700ddd68e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1czGS12eKb9y",
        "outputId": "8386a0be-b119-47a0-9b4a-78268977af93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Test Model 2.h5\")"
      ],
      "metadata": {
        "id": "3P0mqLyb9nzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Generator = generator.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Dataset_NexusHackathon/val\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"training\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLHOi0059uPU",
        "outputId": "0a3f81dc-40f3-41aa-80db-2fab8716b542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(Test_Generator)"
      ],
      "metadata": {
        "id": "FPf6ruyT9_Wi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}